{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dependencies for convenience\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cnn = pd.read_csv(\"basetable_CNN.csv\")\n",
    "data_fox = pd.read_csv(\"basetable_Fox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>Entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>iowa state university</td>\n",
       "      <td>1</td>\n",
       "      <td>iowa</td>\n",
       "      <td>iowa</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Unassigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>iowa state university</td>\n",
       "      <td>2</td>\n",
       "      <td>state</td>\n",
       "      <td>state</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Unassigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>iowa state university</td>\n",
       "      <td>3</td>\n",
       "      <td>university</td>\n",
       "      <td>university</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Profession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>doc2</td>\n",
       "      <td>1</td>\n",
       "      <td>long live britain america true patriots best west</td>\n",
       "      <td>1</td>\n",
       "      <td>long</td>\n",
       "      <td>long</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Unassigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>doc2</td>\n",
       "      <td>1</td>\n",
       "      <td>long live britain america true patriots best west</td>\n",
       "      <td>2</td>\n",
       "      <td>live</td>\n",
       "      <td>live</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Unassigned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 doc_id  sentence_id  \\\n",
       "0           1   doc1            1   \n",
       "1           2   doc1            1   \n",
       "2           3   doc1            1   \n",
       "3           4   doc2            1   \n",
       "4           5   doc2            1   \n",
       "\n",
       "                                            sentence  token_id       token  \\\n",
       "0                              iowa state university         1        iowa   \n",
       "1                              iowa state university         2       state   \n",
       "2                              iowa state university         3  university   \n",
       "3  long live britain america true patriots best west         1        long   \n",
       "4  long live britain america true patriots best west         2        live   \n",
       "\n",
       "        lemma  upos xpos      Entity  \n",
       "0        iowa  NOUN   NN  Unassigned  \n",
       "1       state  NOUN   NN  Unassigned  \n",
       "2  university  NOUN   NN  Profession  \n",
       "3        long   ADJ   JJ  Unassigned  \n",
       "4        live   ADJ   JJ  Unassigned  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1 : Recognition based on memorization only\n",
    "\n",
    "In here, we write a first simplistic model that will learn from the occurences of each word and their assigned entity.\n",
    "<br>\n",
    "The most popular entities for a word will be assigned to any new word when predicting.\n",
    "\n",
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MemoryRecognizer(BaseEstimator, TransformerMixin):\n",
    "    # Building a class based on the sklearn estimators model\n",
    "    # This will allow to easily evaluate the model using sklearn built-in features\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, display_progress=False):\n",
    "        \"\"\"Finds out the most occuring entity for each word\n",
    "        Expects a pd.Series for X & y\"\"\"\n",
    "        voc = {}\n",
    "        self.entities = []\n",
    "            \n",
    "        total_words = len(X)\n",
    "        progress = 0\n",
    "        # For each word, establish a list of dictionaries with the number of times an entity is associated with the word\n",
    "        for word, entity in zip(X,y):\n",
    "            if display_progress == True:\n",
    "                progress += 1\n",
    "                if progress % 10000 == 0:\n",
    "                    print(str(progress), \"/\", str(total_words), \"words classified.\")\n",
    "            \n",
    "            if entity not in self.entities:\n",
    "                self.entities.append(entity)\n",
    "            if word in voc:\n",
    "                if entity in voc[word]:\n",
    "                    voc[word][entity] += 1\n",
    "                else:\n",
    "                    voc[word][entity] = 1\n",
    "            else:\n",
    "                voc[word] = {entity :1}\n",
    "            \n",
    "            self.memory = {}\n",
    "            for word, entities in voc.items():\n",
    "                self.memory[word] = max(entities, key=entities.get)\n",
    "        \n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"Dictionary look-up\"\"\"\n",
    "        return [self.memory.get(word, 'Unassigned') for word in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Here, we will assess the model's performance in two ways.\n",
    "<br> \n",
    "The first is getting a predicted value for each word in the cnn_data set, using cross_validated predicting.\n",
    "<br>\n",
    "This means the dataset is split in a k-fold fashion (5 fold here), and all the words pass through the prediction method at some point, as the testing (unseen) set.\n",
    "This allows for evaluation metrics for the whole dataset while avoiding biased results.\n",
    "\n",
    "<br> \n",
    "The second way to evaluate the model is to test it on the opposite data set (train on cnn, test on fox) or vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 / 32459 words classified.\n",
      "20000 / 32459 words classified.\n",
      "30000 / 32459 words classified.\n",
      "10000 / 32459 words classified.\n",
      "20000 / 32459 words classified.\n",
      "30000 / 32459 words classified.\n",
      "10000 / 32459 words classified.\n",
      "20000 / 32459 words classified.\n",
      "30000 / 32459 words classified.\n",
      "10000 / 32459 words classified.\n",
      "20000 / 32459 words classified.\n",
      "30000 / 32459 words classified.\n",
      "10000 / 32460 words classified.\n",
      "20000 / 32460 words classified.\n",
      "30000 / 32460 words classified.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       1.00      0.96      0.98       713\n",
      "Organization       1.00      0.92      0.96       193\n",
      " Personality       1.00      0.95      0.97       713\n",
      "  Profession       1.00      0.98      0.99      2469\n",
      "    Religion       1.00      0.91      0.95        34\n",
      "  Unassigned       1.00      1.00      1.00     36452\n",
      "\n",
      " avg / total       1.00      1.00      1.00     40574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = data_fox.token.values.tolist()\n",
    "entities = data_fox.Entity.values.tolist()\n",
    "\n",
    "pred = cross_val_predict(estimator=MemoryRecognizer(), \n",
    "                         X=words, y=entities, cv=5, \n",
    "                         fit_params={\"display_progress\":True})\n",
    "\n",
    "print(classification_report(y_pred = pred, y_true=entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on CNN / Testing on Fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 / 31356 words classified.\n",
      "20000 / 31356 words classified.\n",
      "30000 / 31356 words classified.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       1.00      0.96      0.98       713\n",
      "Organization       1.00      0.85      0.92       193\n",
      " Personality       1.00      0.95      0.97       713\n",
      "  Profession       1.00      0.97      0.99      2469\n",
      "    Religion       1.00      1.00      1.00        34\n",
      "  Unassigned       1.00      1.00      1.00     36452\n",
      "\n",
      " avg / total       1.00      1.00      1.00     40574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recognizer = MemoryRecognizer()\n",
    "\n",
    "words_cnn = data_cnn.token.values.tolist()\n",
    "entities_cnn = data_cnn.Entity.values.tolist()\n",
    "\n",
    "words_fox = data_fox.token.values.tolist()\n",
    "entities_fox = data_fox.Entity.values.tolist()\n",
    "\n",
    "recognizer.fit(X=words_cnn, y=entities_cnn, display_progress=True)\n",
    "preds = recognizer.predict(X=words_fox)\n",
    "\n",
    "print(classification_report(y_pred=preds, y_true=entities_fox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on Fox / Testing on CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 / 40574 words classified.\n",
      "20000 / 40574 words classified.\n",
      "30000 / 40574 words classified.\n",
      "40000 / 40574 words classified.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       1.00      0.96      0.98       581\n",
      "Organization       1.00      0.82      0.90       135\n",
      " Personality       1.00      0.96      0.98       478\n",
      "  Profession       1.00      0.98      0.99      2308\n",
      "    Religion       1.00      0.95      0.98        22\n",
      "  Unassigned       1.00      1.00      1.00     27832\n",
      "\n",
      " avg / total       1.00      1.00      1.00     31356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recognizer = MemoryRecognizer()\n",
    "\n",
    "words_fox = data_fox.token.values.tolist()\n",
    "entities_fox = data_fox.Entity.values.tolist()\n",
    "\n",
    "words_cnn = data_cnn.token.values.tolist()\n",
    "entities_cnn = data_cnn.Entity.values.tolist()\n",
    "\n",
    "recognizer.fit(X=words_fox, y=entities_fox, display_progress=True)\n",
    "preds = recognizer.predict(X=words_cnn)\n",
    "\n",
    "print(classification_report(y_pred=preds, y_true=entities_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2 : Simple classification model\n",
    "\n",
    "Here, we derive simple features from each word and use those to try to predict their entity type, using a Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(word):\n",
    "    return pd.Series([word.istitle(), word.islower(), \n",
    "                      len(word), word.isdigit(), word.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>istitle</th>\n",
       "      <th>islower</th>\n",
       "      <th>length</th>\n",
       "      <th>isdigit</th>\n",
       "      <th>isalpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   istitle  islower  length  isdigit  isalpha\n",
       "0    False     True       4    False     True\n",
       "1    False     True       5    False     True\n",
       "2    False     True      10    False     True\n",
       "3    False     True       4    False     True\n",
       "4    False     True       4    False     True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_fox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using cross-validated predictions (Fox dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       0.00      0.00      0.00       713\n",
      "Organization       0.00      0.00      0.00       193\n",
      " Personality       0.00      0.00      0.00       713\n",
      "  Profession       0.00      0.00      0.00      2469\n",
      "    Religion       0.00      0.00      0.00        34\n",
      "  Unassigned       0.90      1.00      0.95     36452\n",
      "\n",
      " avg / total       0.81      0.90      0.85     40574\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "features_fox = data_fox.token.apply(get_features)\n",
    "features_fox.columns = [\"istitle\", \"islower\", \n",
    "                      \"length\", \"isdigit\", \"isalpha\"]\n",
    "preds = cross_val_predict(RandomForestClassifier(n_estimators=500),\n",
    "                         X=features_fox, y=data_fox.Entity, cv=5)\n",
    "\n",
    "print(classification_report(y_pred=preds, y_true=data_fox.Entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on Fox / Testing on CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fox = data_fox.token.apply(get_features)\n",
    "X_fox.columns = [\"istitle\", \"islower\", \n",
    "                      \"length\", \"isdigit\", \"isalpha\"]\n",
    "\n",
    "X_cnn = data_cnn.token.apply(get_features)\n",
    "X_cnn.columns = [\"istitle\", \"islower\", \n",
    "                      \"length\", \"isdigit\", \"isalpha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       0.00      0.00      0.00       581\n",
      "Organization       0.00      0.00      0.00       135\n",
      " Personality       0.00      0.00      0.00       478\n",
      "  Profession       0.00      0.00      0.00      2308\n",
      "    Religion       0.00      0.00      0.00        22\n",
      "  Unassigned       0.89      1.00      0.94     27832\n",
      "\n",
      " avg / total       0.79      0.89      0.83     31356\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X=X_fox, y=data_fox.Entity)\n",
    "\n",
    "preds = rfc.predict(X_cnn)\n",
    "print(classification_report(y_pred=preds, y_true=data_cnn.Entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on CNN / Testing on Fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       0.00      0.00      0.00       713\n",
      "Organization       0.00      0.00      0.00       193\n",
      " Personality       0.00      0.00      0.00       713\n",
      "  Profession       0.00      0.00      0.00      2469\n",
      "    Religion       0.00      0.00      0.00        34\n",
      "  Unassigned       0.90      1.00      0.95     36452\n",
      "\n",
      " avg / total       0.81      0.90      0.85     40574\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X=X_cnn, y=data_cnn.Entity)\n",
    "\n",
    "preds = rfc.predict(X_fox)\n",
    "print(classification_report(y_pred=preds, y_true=data_fox.Entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results using a simple classification method are terrible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3 : Combination of featurization, memorization & context information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this final model, we combine an approach based on memory of previously seen words, word featurization, context information, and classify the resulting observations using a Random Forest classifier. \n",
    "The memory-based part is obtained by learning the most common entity identifications for each word. Once it is trained, if a new word has already been seen, it will be classified as it was in the past. \n",
    "\n",
    "\n",
    "In addition to this major feature, other information are drawn from the word itself. It includes whether the word contains uppercase, lowercase letters, whether it is in the title format, how many characters it is made of and whether there is digits within the word. The part of speech tag is also retrieved.\n",
    "These features are also retrieved for the preceding word and the following one, and combined to form a feature space.\n",
    "\n",
    "Finally, these variables are used to predict the named entity using a random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Featurizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memory_tagger = MemoryRecognizer()\n",
    "        self.tag_encoder = LabelEncoder()\n",
    "        self.pos_encoder = LabelEncoder()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.pos = X.upos.values.tolist()\n",
    "        self.memory_tagger.fit(X.token, y)\n",
    "        entities = X.Entity.values.tolist()\n",
    "        self.pos_encoder.fit(self.pos)\n",
    "        self.tag_encoder.fit(X.Entity)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        def pos_default(p):\n",
    "            if p in self.pos:\n",
    "                return self.pos_encoder.transform([p])[0]\n",
    "            else:\n",
    "                return -1\n",
    "        \n",
    "        pos = X.upos.values.tolist()\n",
    "        words = X.token.values.tolist()\n",
    "        out = []\n",
    "        for i in range(len(words)):\n",
    "            w = words[i]\n",
    "            p = pos[i]\n",
    "            if i < len(words) - 1:\n",
    "                wp = self.tag_encoder.transform(self.memory_tagger.predict([words[i+1]]))\n",
    "                posp = pos_default(pos[i+1])\n",
    "            else:\n",
    "                wp = self.tag_encoder.transform(['Unassigned'])[0]\n",
    "                posp = pos_default(\".\")\n",
    "                \n",
    "            if i > 0:\n",
    "                if words[i-1] != \".\":\n",
    "                    wm = self.tag_encoder.transform(self.memory_tagger.predict([words[i-1]]))[0]\n",
    "                    posm = pos_default(pos[i-1])\n",
    "                    \n",
    "                else:\n",
    "                    wm = self.tag_encoder.transform([\"Unassigned\"])[0]\n",
    "                    posm = pos_default(\".\")\n",
    "                    \n",
    "            else:\n",
    "                posm = pos_default(\".\")\n",
    "                wm = self.tag_encoder.transform([\"Unassigned\"])[0]\n",
    "                \n",
    "            out.append(np.array([w.istitle(), w.islower(), w.isupper(), len(w), w.isdigit(), w.isalpha(),\n",
    "                                 self.tag_encoder.transform(self.memory_tagger.predict([w]))[0],\n",
    "                                 pos_default(p), wp, wm, posp, posm]))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using cross-validated predictions (Fox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "X_fox = data_fox[[\"token\", \"upos\", \"Entity\"]]\n",
    "\n",
    "y_fox = data_fox.Entity.values.tolist()\n",
    "\n",
    "pred = cross_val_predict(Pipeline([(\"feature_map\", Featurizer()), \n",
    "                                   (\"clf\", RandomForestClassifier(n_estimators=20, n_jobs=3))]),\n",
    "                         X=data_fox, y=y_fox, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       0.99      0.95      0.97       713\n",
      "Organization       0.98      0.82      0.90       193\n",
      " Personality       0.99      0.95      0.97       713\n",
      "  Profession       0.99      0.98      0.98      2469\n",
      "    Religion       1.00      0.47      0.64        34\n",
      "  Unassigned       1.00      1.00      1.00     36452\n",
      "\n",
      " avg / total       1.00      1.00      1.00     40574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=pred, y_true=y_fox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fox = data_fox[[\"token\", \"upos\", \"Entity\"]]\n",
    "y_fox = data_fox.Entity.values.tolist()\n",
    "\n",
    "X_cnn = data_cnn[[\"token\", \"upos\", \"Entity\"]]\n",
    "y_cnn = data_cnn.Entity.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on Fox / Testing on CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([(\"feature_map\", Featurizer()), \n",
    "                (\"clf\", RandomForestClassifier(n_estimators=20, n_jobs=3))])\n",
    "pipe = pipe.fit(X_fox, y_fox)\n",
    "\n",
    "pred_cnn = pipe.predict(X_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       1.00      0.95      0.98       581\n",
      "Organization       0.96      0.80      0.87       135\n",
      " Personality       0.99      0.95      0.97       478\n",
      "  Profession       1.00      0.98      0.99      2308\n",
      "    Religion       1.00      0.68      0.81        22\n",
      "  Unassigned       1.00      1.00      1.00     27832\n",
      "\n",
      " avg / total       1.00      1.00      1.00     31356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=pred_cnn, y_true=y_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on CNN / Testing on Fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([(\"feature_map\", Featurizer()), \n",
    "                (\"clf\", RandomForestClassifier(n_estimators=20, n_jobs=3))])\n",
    "pipe = pipe.fit(X_fox, y_fox)\n",
    "\n",
    "pred_cnn = pipe.predict(X_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Hobbies       1.00      0.96      0.98       581\n",
      "Organization       1.00      0.82      0.90       135\n",
      " Personality       1.00      0.95      0.98       478\n",
      "  Profession       1.00      0.98      0.99      2308\n",
      "    Religion       1.00      0.95      0.98        22\n",
      "  Unassigned       1.00      1.00      1.00     27832\n",
      "\n",
      " avg / total       1.00      1.00      1.00     31356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=pred_cnn, y_true=y_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outputting results in a standard format for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>token</th>\n",
       "      <th>upos</th>\n",
       "      <th>Entity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc1</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>Personality</td>\n",
       "      <td>Personality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc2</td>\n",
       "      <td>fav</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Unassigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc2</td>\n",
       "      <td>youtuber</td>\n",
       "      <td>ADP</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Unassigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc2</td>\n",
       "      <td>moesargi</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Unassigned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc2</td>\n",
       "      <td>fav</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Unassigned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id       token  upos       Entity        label\n",
       "0   doc1  optimistic   ADJ  Personality  Personality\n",
       "1   doc2         fav  VERB   Unassigned   Unassigned\n",
       "2   doc2    youtuber   ADP   Unassigned   Unassigned\n",
       "3   doc2    moesargi  NOUN   Unassigned   Unassigned\n",
       "4   doc2         fav  NOUN   Unassigned   Unassigned"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data_cnn[[\"doc_id\", \"token\", \"upos\", \"Entity\"]]\n",
    "data2 = pd.DataFrame(pred_cnn, columns=[\"label\"])\n",
    "output_results = pd.concat([data1, data2], axis=1,ignore_index=True)\n",
    "output_results.columns = [[\"doc_id\", \"token\", \"upos\", \"Entity\", \"label\"]]\n",
    "output_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_results.to_csv(\"Random Forest Fox Predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying the decision-making of the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word.memoryEntity</td>\n",
       "      <td>0.916774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>word.postag</td>\n",
       "      <td>0.035291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length</td>\n",
       "      <td>0.024707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prevword.memoryEntity</td>\n",
       "      <td>0.006488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nextword.memoryEntity</td>\n",
       "      <td>0.006335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Variable  Importance\n",
       "6      word.memoryEntity    0.916774\n",
       "7            word.postag    0.035291\n",
       "3                 length    0.024707\n",
       "9  prevword.memoryEntity    0.006488\n",
       "8  nextword.memoryEntity    0.006335"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intelligible list of variable names\n",
    "vars = [\"word.istitle\", \"word.islower\", \"word.isupper\", \"length\", \"word.isdigit\", \"word.isalpha\",\n",
    "\"word.memoryEntity\", \"word.postag\", \"nextword.memoryEntity\", \"prevword.memoryEntity\",\n",
    "\"nextword.postag\", \"prevword.postag\"]\n",
    "\n",
    "vars_importances = pipe.named_steps.clf.feature_importances_\n",
    "\n",
    "var_ranking = []\n",
    "for var, imp in zip(vars, vars_importances):\n",
    "    var_ranking.append([var, imp])\n",
    "df = pd.DataFrame(var_ranking, columns=[\"Variable\", \"Importance\"]).sort_values(\"Importance\", ascending=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
